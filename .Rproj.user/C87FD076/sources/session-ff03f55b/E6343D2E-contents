#' Function for estimating a Poisson-Lindley-Gamma (i.e., Negative Binomial-Lindley) regression model
#'
#' @name poisLindGamma
#' @param formula an R formula.
#' @param method a method to use for optimization in the maximum likelihood estimation. For options, see \code{\link[maxLik]{maxLik}}.
#' @param data a dataframe that has all of the variables in the \code{formula} and \code{rpar_formula}.
#' @param ndraws the number of Halton draws to use for the integration over the gamma distribution.
#' @param max.iters the maximum number of iterations to allow the optimization method to perform.
#' @param print.level determines the level of verbosity for printing details of the optimization as it is computed. A value of 0 does not print out any information, a value of 1 prints minimal information, and a value of 2 prints the most information.
#'
#' @import nlme  maxLik  MASS  stats modelr
#' @include plindGamma.R
#'
#' @details
#' The Poisson-Lindley-Gamma regression is based on a compound Poisson-Lindley-Gamma distribution. Details of the distribution can be seen at \code{\link[flexCountReg]{dplindGamma}}.
#'
#' The mean for the regression model is:
#' \deqn{\mu=e^{X\beta}}
#'
#' The variance function is defined as:
#' \deqn{\sigma^2=\mu+\left(\alpha+1-\frac{2}{(\theta+2)^2}\right)\mu^2}
#'
#' It should be noted that the p-value for the parameters `ln(theta)` and `ln(alpha)` in the model summary are testing if the parameter `theta` and `alpha` are equal to a value of 1.
#'
#'
#' @examples
#' \dontrun{
#'
#' ## Poisson-Lindley-Gamma Model
#' data("washington_roads")
#' washington_roads$AADTover10k <- ifelse(washington_roads$AADT>10000,1,0) # create a dummy variable
#' poislindgamma.mod <- poisLindGamma(Animal ~ lnaadt + lnlength + speed50 +
#'                                 ShouldWidth04 + AADTover10k,
#'                                 data=washington_roads,
#'                                 ndraws=100,
#'                                 max.iters = 1000)
#' summary(poislindgamma.mod)}
#' @export
poisLindGamma <- function(formula, data, method = 'BHHH', ndraws=1500, 
                          max.iters = 1000, print.level = 0) {
  
  mod_df <- stats::model.frame(formula, data)
  X <- as.matrix(modelr::model_matrix(data, formula))
  y <- as.numeric(stats::model.response(mod_df))
  x_names <- colnames(X)
  
  # Use the Poisson as starting values
  p_model <- MASS::glm.nb(formula, data = data)
  start <- unlist(p_model$coefficients)
  start <- append(start, 0) # initial log(theta)
  full_start <- append(start, 0) # initial log(alpha)
  
  modparams <- as.numeric(length(full_start))
  
  dplindGamma_log <- function(x, mean, theta, alpha, ndraws) {
    p <- dplindGamma(x, mean=mean, theta=theta, alpha=alpha, ndraws=ndraws, log=TRUE)
    return(p)
  }
  
  # Gradient Function
  gradFun <- function(beta, y, X) {
    coefs <- beta[1:(modparams - 2)]
    ln_theta <- beta[(modparams - 1)]
    ln_alpha <- beta[modparams]
    theta <- exp(ln_theta)
    alpha <- exp(ln_alpha)
    
    predicted <- exp(X %*% coefs)
    
    grad <- matrix(0, ncol = modparams, nrow = length(y))
    
    for (i in 1:length(y)) {
      mu_i <- predicted[i]
      p_mu <- dplindGamma(y[i], mean=mu_i, theta=theta, alpha=alpha, ndraws=ndraws)
      p_mu1 <- dplindGamma(y[i], mean=mu_i * (1 + 1e-5), theta=theta, alpha=alpha, ndraws=ndraws)
      grad[i, 1:(modparams - 2)] <- (log(p_mu1) - log(p_mu)) / (1e-5 * mu_i) * mu_i * X[i, ]
    }
    
    for (i in 1:length(y)) {
      p_theta <- dplindGamma(y[i], mean=predicted[i], theta=theta, alpha=alpha, ndraws=ndraws)
      p_theta1 <- dplindGamma(y[i], mean=predicted[i], theta=theta * (1 + 1e-5), alpha=alpha, ndraws=ndraws)
      grad[i, (modparams - 1)] <- (log(p_theta1) - log(p_theta)) / (1e-5 * theta) * theta
    }
    
    for (i in 1:length(y)) {
      p_alpha <- dplindGamma(y[i], mean=predicted[i], theta=theta, alpha=alpha, ndraws=ndraws)
      p_alpha1 <- dplindGamma(y[i], mean=predicted[i], theta=theta, alpha=alpha * (1 + 1e-5), ndraws=ndraws)
      grad[i, modparams] <- (log(p_alpha1) - log(p_alpha)) / (1e-5 * alpha) * alpha
    }
    
    return(grad)
  }
  
  # Hessian Function
  hessFun <- function(beta, y, X) {
    coefs <- beta[1:(modparams - 2)]
    ln_theta <- beta[(modparams - 1)]
    ln_alpha <- beta[modparams]
    theta <- exp(ln_theta)
    alpha <- exp(ln_alpha)
    
    predicted <- exp(X %*% coefs)
    
    hess <- matrix(0, ncol = modparams, nrow = modparams)
    
    for (i in 1:length(y)) {
      mu_i <- predicted[i]
      p_mu <- dplindGamma(y[i], mean=mu_i, theta=theta, alpha=alpha, ndraws=ndraws)
      p_mu1 <- dplindGamma(y[i], mean=mu_i * (1 + 1e-5), theta=theta, alpha=alpha, ndraws=ndraws)
      p_mu2 <- dplindGamma(y[i], mean=mu_i * (1 + 2e-5), theta=theta, alpha=alpha, ndraws=ndraws)
      hess[1:(modparams - 2), 1:(modparams - 2)] <- hess[1:(modparams - 2), 1:(modparams - 2)] +
        (log(p_mu2) - 2 * log(p_mu1) + log(p_mu)) / (1e-5^2 * mu_i^2) * mu_i^2 * (X[i, ] %*% t(X[i, ]))
    }
    
    for (i in 1:length(y)) {
      p_theta <- dplindGamma(y[i], mean=predicted[i], theta=theta, alpha=alpha, ndraws=ndraws)
      p_theta1 <- dplindGamma(y[i], mean=predicted[i], theta=theta * (1 + 1e-5), alpha=alpha, ndraws=ndraws)
      p_theta2 <- dplindGamma(y[i], mean=predicted[i], theta=theta * (1 + 2e-5), alpha=alpha, ndraws=ndraws)
      hess[(modparams - 1), (modparams - 1)] <- hess[(modparams - 1), (modparams - 1)] +
        (log(p_theta2) - 2 * log(p_theta1) + log(p_theta)) / (1e-5^2 * theta^2) * theta^2
    }
    
    for (i in 1:length(y)) {
      p_alpha <- dplindGamma(y[i], mean=predicted[i], theta=theta, alpha=alpha, ndraws=ndraws)
      p_alpha1 <- dplindGamma(y[i], mean=predicted[i], theta=theta, alpha=alpha * (1 + 1e-5), ndraws=ndraws)
      p_alpha2 <- dplindGamma(y[i], mean=predicted[i], theta=theta, alpha=alpha * (1 + 2e-5), ndraws=ndraws)
      hess[modparams, modparams] <- hess[modparams, modparams] +
        (log(p_alpha2) - 2 * log(p_alpha1) + log(p_alpha)) / (1e-5^2 * alpha^2) * alpha^2
    }
    
    return(hess)
  }
  
  reg.run <- function(beta, y, X){
    pars <- length(beta)-2
    distpars <- as.vector(unlist(beta[(pars+1):length(beta)]))
    
    coefs <- as.vector(unlist(beta[1:pars]))
    theta <- exp(distpars[1])
    alpha <- exp(distpars[2])
    
    predicted <- exp(X %*% coefs)
    
    probs <- dplindGamma(y, mean=predicted, theta=theta, alpha=alpha, ndraws=ndraws)
    
    ll <- sum(log(probs))
    if (method == 'bhhh' | method == 'BHHH'){
      return(log(probs))
    } else{return(ll)}
  }
  
  fit <- maxLik::maxLik(reg.run,
                        start = full_start,
                        y = y,
                        X = X,
                        grad = if (method == 'BHHH') gradFun else function(...) colSums(gradFun(...)),
                        hess = hessFun,
                        method = method,
                        control = list(iterlim = max.iters, printLevel = print.level))
  
  beta_est <- fit$estimate
  npars <- length(beta_est)-2
  beta_pred <- as.vector(unlist(beta_est[1:npars]))
  distpars <- as.vector(unlist(beta_est[(npars+1):length(beta_est)]))
  
  fit$beta_pred <- beta_pred # save coefficients for predictions
  
  mu <- exp(X %*% beta_pred)
  fit$theta <- exp(distpars[1])
  fit$alpha <- exp(distpars[2])
  
  x_names <- append(x_names, 'ln(theta)')
  x_names <- append(x_names, 'ln(alpha)')
  names(fit$estimate) <- x_names
  
  fit$predictions <- mu
  
  fit$formula <- formula
  fit$observed <- y
  fit$residuals <- y - fit$predictions
  fit$LL <- fit$maximum # The log-likelihood of the model
  fit$modelType <- "poisLindGamma"
  
  return(fit)
}
